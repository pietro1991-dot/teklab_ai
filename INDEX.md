# ğŸ“‘ Spirituality AI - Indice Completo Progetto

Navigazione rapida a tutte le risorse del progetto.

---

## ğŸš€ Start Here

### Per Nuovi Utenti
1. **[README.md](README.md)** - Overview progetto e quick start
2. **[docs/QUICK_START.md](docs/QUICK_START.md)** - Setup passo-passo
3. **[docs/WORKFLOW_GUIDA.md](docs/WORKFLOW_GUIDA.md)** - Workflow completo

### Per Sviluppatori
1. **[docs/](docs/)** - Tutta la documentazione tecnica
2. **[tests/](tests/)** - Test suite completa
3. **[scripts/](scripts/)** - Scripts operativi

---

## ğŸ“š Documentazione (`docs/`)

| File | Descrizione | Usa quando... |
|------|-------------|---------------|
| **[README.md](docs/README.md)** | Indice documentazione | Cerchi una guida specifica |
| **[QUICK_START.md](docs/QUICK_START.md)** | Setup iniziale | Prima installazione |
| **[PROMPT_SYSTEM_GUIDE.md](docs/PROMPT_SYSTEM_GUIDE.md)** | Sistema prompt configurabili | Crei chunk o personalizzi metadata |
| **[LLAMA_LOCAL_TRAINING_GUIDE.md](docs/LLAMA_LOCAL_TRAINING_GUIDE.md)** | Fine-tuning Llama | Vuoi addestrare il modello |
| **[WORKFLOW_GUIDA.md](docs/WORKFLOW_GUIDA.md)** | Pipeline completa | Capire architettura end-to-end |
| **[ANALISI_FINALE.md](docs/ANALISI_FINALE.md)** | Analisi tecnica | Decisioni architetturali |
| **[CHECKLIST_VERIFICA.md](docs/CHECKLIST_VERIFICA.md)** | Checklist QA | Verifica/troubleshooting |

---

## ğŸ§ª Testing (`tests/`)

| File | Descrizione | Comando |
|------|-------------|---------|
| **[README.md](tests/README.md)** | Guida test suite | - |
| **test_chunk_prompts.py** | Test prompt system | `python tests/test_chunk_prompts.py` |
| **test_api.py** | Test backend Flask | `python tests/test_api.py` |
| **test_imports.py** | Test import moduli | `python tests/test_imports.py` |

---

## ğŸ› ï¸ Scripts Operativi (`scripts/`)

| Script | Funzione | Comando Esempio |
|--------|----------|-----------------|
| **1_download_llama.py** | Download modello Llama | `python scripts/1_download_llama.py` |
| **2_generate_embeddings.py** | Crea embeddings RAG | `python scripts/2_generate_embeddings.py` |
| **3_create_chunks_with_llama.py** | Genera chunk con Llama | `python scripts/3_create_chunks_with_llama.py --days 1 --prompt-variant detailed` |
| **4_create_training_dataset.py** | Crea dataset training | `python scripts/4_create_training_dataset.py` |
| **5_train_llama_rag.py** | Fine-tuning Llama | `python scripts/5_train_llama_rag.py` |
| **6_chatbot.py** | Chatbot interattivo CLI | `python scripts/6_chatbot.py` |

---

## ğŸ¨ Frontend & Backend

### UI Experience (`UI_experience/`)
**ChatGPT-style Web Interface**

| File | Descrizione |
|------|-------------|
| **[README.md](UI_experience/README.md)** | Documentazione UI |
| **index.html** | Main interface |
| **assets/js/app.js** | Application logic |
| **assets/js/api.js** | Backend communication |
| **assets/css/main.css** | ChatGPT-style design |

**Avvio:**
1. Avvia backend: `python backend_api/app.py`
2. Apri: `UI_experience/index.html` nel browser

---

### Backend API (`backend_api/`)
**Flask REST API**

| File | Descrizione |
|------|-------------|
| **app.py** | Flask server (5 endpoints) |
| **requirements.txt** | Dipendenze backend |

**Endpoints:**
- `GET /health` - Health check
- `POST /chat` - Invia messaggio
- `GET /history` - Cronologia conversazioni
- `POST /clear` - Pulisci cronologia
- `GET /stats` - Statistiche sistema

**Avvio:**
```bash
python backend_api/app.py
```

---

## ğŸ§  AI System (`ai_system/`)

### Modelli (`ai_system/src/models/`)
- **llama_rag_model.py** - Implementazione base Llama RAG
- **llama_rag_wrapper.py** - Wrapper con auto-detection checkpoint
- **rag_logger.py** - Logging conversazioni

### Configurazione (`ai_system/src/config/`)
- **model_config.py** - Configurazioni modelli (Llama 2/3, QLoRA)

### Training (`ai_system/src/training/`)
- **conversation_logger.py** - Log training conversations
- **training_dataset/** - Dataset preparati per fine-tuning

### Embeddings (`ai_system/Embedding/`)
- Vector database e embeddings per RAG retrieval

---

## ğŸ’¬ Prompt System (`Prompt/`)

| File | Descrizione |
|------|-------------|
| **prompts_config.py** | System prompt chatbot principale |
| **chunk_prompts_config.py** | Prompt configurabili chunk creation |
| **chunk_creation_instructions.txt** | Istruzioni manuali creazione chunk (per Copilot) |

**Varianti prompt disponibili:**
- `default` - Bilanciato qualitÃ /velocitÃ 
- `concise` - Estrazione rapida
- `detailed` - Massima qualitÃ 
- `multilingual` - Language-aware

---

## ğŸ“‚ Knowledge Base (`Fonti/`)

### Struttura
```
Fonti/
â””â”€â”€ Autori/
    â””â”€â”€ Mathias de Stefano/
        â”œâ”€â”€ Originali/
        â”‚   â””â”€â”€ Pyramid.mathias/
        â”‚       â”œâ”€â”€ Day_1_Transcript.txt
        â”‚       â”œâ”€â”€ Day_2_Transcript.txt
        â”‚       â””â”€â”€ ...
        â””â”€â”€ Processati/
            â””â”€â”€ Pyramid Course/
                â”œâ”€â”€ chunks/
                â”‚   â”œâ”€â”€ day01/
                â”‚   â”œâ”€â”€ day02/
                â”‚   â””â”€â”€ ...
                â”œâ”€â”€ metadata/
                â”œâ”€â”€ keywords/
                â”œâ”€â”€ quotes/
                â””â”€â”€ qa_pairs/
```

**Originali**: Trascrizioni raw  
**Processati**: Chunk strutturati JSON generati da script 3

---

## ğŸ”§ Configurazione

### File Principali
- **START_CHATBOT.bat** - Avvio rapido chatbot (Windows)
- **.gitignore** - Git ignore rules
- **README_OLD.md** - Documentazione legacy

### Requirements
- **BOT/requirements.txt** - Dipendenze bot principale
- **backend_api/requirements.txt** - Dipendenze Flask API

---

## ğŸ¯ Workflow Tipici

### 1. Setup Iniziale
```bash
# 1. Installa dipendenze
pip install -r BOT/requirements.txt

# 2. Login HuggingFace
huggingface-cli login

# 3. Download Llama
python scripts/1_download_llama.py

# 4. Genera embeddings
python scripts/2_generate_embeddings.py
```

### 2. Creazione Chunk
```bash
# Genera chunk per Day 1 con qualitÃ  massima
python scripts/3_create_chunks_with_llama.py --days 1 --prompt-variant detailed

# Test sistema prompt
python tests/test_chunk_prompts.py
```

### 3. Training
```bash
# 1. Crea dataset
python scripts/4_create_training_dataset.py

# 2. Fine-tuning
python scripts/5_train_llama_rag.py

# 3. Usa modello fine-tunato
python scripts/6_chatbot.py
```

### 4. Deploy Web Interface
```bash
# Terminal 1: Backend
python backend_api/app.py

# Terminal 2: Apri UI
# Apri UI_experience/index.html nel browser
```

---

## ğŸ“Š Struttura Completa Progetto

```
spirituality.ai/
â”‚
â”œâ”€â”€ ğŸ“„ INDEX.md                           â† Stai qui!
â”œâ”€â”€ ğŸ“„ README.md                          â† Overview progetto
â”œâ”€â”€ ğŸ“„ START_CHATBOT.bat                  â† Quick launch
â”‚
â”œâ”€â”€ ğŸ“š docs/                              â† Documentazione
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ QUICK_START.md
â”‚   â”œâ”€â”€ PROMPT_SYSTEM_GUIDE.md
â”‚   â”œâ”€â”€ LLAMA_LOCAL_TRAINING_GUIDE.md
â”‚   â”œâ”€â”€ WORKFLOW_GUIDA.md
â”‚   â”œâ”€â”€ ANALISI_FINALE.md
â”‚   â””â”€â”€ CHECKLIST_VERIFICA.md
â”‚
â”œâ”€â”€ ğŸ§ª tests/                             â† Test suite
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ test_chunk_prompts.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â””â”€â”€ test_imports.py
â”‚
â”œâ”€â”€ ğŸ› ï¸ scripts/                           â† Scripts operativi
â”‚   â”œâ”€â”€ 1_download_llama.py
â”‚   â”œâ”€â”€ 2_generate_embeddings.py
â”‚   â”œâ”€â”€ 3_create_chunks_with_llama.py
â”‚   â”œâ”€â”€ 4_create_training_dataset.py
â”‚   â”œâ”€â”€ 5_train_llama_rag.py
â”‚   â””â”€â”€ 6_chatbot.py
â”‚
â”œâ”€â”€ ğŸ¨ UI_experience/                     â† Frontend web
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ assets/
â”‚       â”œâ”€â”€ css/
â”‚       â””â”€â”€ js/
â”‚
â”œâ”€â”€ ğŸ”Œ backend_api/                       â† Backend Flask
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ§  ai_system/                         â† Core AI
â”‚   â”œâ”€â”€ Embedding/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ models/
â”‚       â”œâ”€â”€ config/
â”‚       â””â”€â”€ training/
â”‚
â”œâ”€â”€ ğŸ’¬ Prompt/                            â† Prompt system
â”‚   â”œâ”€â”€ prompts_config.py
â”‚   â”œâ”€â”€ chunk_prompts_config.py
â”‚   â””â”€â”€ chunk_creation_instructions.txt
â”‚
â”œâ”€â”€ ğŸ“‚ Fonti/                             â† Knowledge base
â”‚   â””â”€â”€ Autori/
â”‚       â””â”€â”€ Mathias de Stefano/
â”‚           â”œâ”€â”€ Originali/
â”‚           â””â”€â”€ Processati/
â”‚
â””â”€â”€ ğŸ¤– BOT/                               â† Bot config
    â””â”€â”€ requirements.txt
```

---

## ğŸ†˜ Help

### Ho bisogno di...

| Bisogno | Vai a... |
|---------|----------|
| **Setup iniziale** | [docs/QUICK_START.md](docs/QUICK_START.md) |
| **Creare chunk** | [docs/PROMPT_SYSTEM_GUIDE.md](docs/PROMPT_SYSTEM_GUIDE.md) |
| **Addestrare Llama** | [docs/LLAMA_LOCAL_TRAINING_GUIDE.md](docs/LLAMA_LOCAL_TRAINING_GUIDE.md) |
| **Capire architettura** | [docs/WORKFLOW_GUIDA.md](docs/WORKFLOW_GUIDA.md) |
| **Risolvere problemi** | [docs/CHECKLIST_VERIFICA.md](docs/CHECKLIST_VERIFICA.md) |
| **Testare sistema** | [tests/README.md](tests/README.md) |
| **API reference** | `backend_api/app.py` (commenti inline) |

---

## ğŸ”— Links Utili

### Esterni
- **HuggingFace Llama**: https://huggingface.co/meta-llama
- **LoRA Paper**: https://arxiv.org/abs/2106.09685
- **RAG Tutorial**: https://python.langchain.com/docs/use_cases/question_answering/

### Interni Progetto
- **Repository**: [GitHub Link if available]
- **Issues**: [GitHub Issues if available]
- **Discussions**: [GitHub Discussions if available]

---

**Ultimo aggiornamento**: 31 Ottobre 2025  
**Versione Progetto**: 2.0.0  
**Status**: âœ… Produzione
