# ğŸ¦™ WORKFLOW COMPLETO - SPIRITUALITY AI

## ğŸ“‹ ORDINE DI ESECUZIONE SCRIPT

Gli script sono numerati per indicare la sequenza corretta di esecuzione.

---

## ğŸ”„ SETUP INIZIALE (UNA VOLTA)

### **1ï¸âƒ£ Download Modello Llama (OBBLIGATORIO)**
```powershell
python scripts\1_download_llama.py --verify
```
**Cosa fa:**
- Scarica Llama 2 7B da HuggingFace (~13GB)
- Salva in `ai_system/models/Llama-2-7b-chat-hf/`
- Verifica funzionamento modello

**Quando eseguire:**
- âœ… Una volta all'inizio
- â­ï¸ Mai piÃ¹ necessario dopo il primo download

**Output atteso:**
```
âœ… Modello scaricato: ai_system/models/Llama-2-7b-chat-hf/
âœ… Verifica completata: tokenizer e config OK
```

---

## ğŸ“š CREAZIONE KNOWLEDGE BASE

### **2ï¸âƒ£ Genera Embeddings RAG (Dopo avere chunk)**
```powershell
python scripts\2_generate_embeddings.py
```
**Cosa fa:**
- Legge tutti i chunk da `Fonti/Autori/.../Processati/*/chunks/`
- Genera embeddings vettoriali (384-dim)
- Salva cache in `ai_system/Embedding/embeddings_cache.pkl`

**Quando eseguire:**
- âœ… Dopo aver creato nuovi chunk (manualmente o con script 3)
- âœ… Ogni volta che aggiungi nuove trascrizioni processate
- â­ï¸ Non serve se non hai modificato i chunk

**Output atteso:**
```
ğŸ“š Caricamento dati da Fonti...
âœ… Trovate 1 fonti
ğŸ“Š DATI CARICATI:
   â€¢ Capitoli: 60
   â€¢ Chunks: 450
ğŸ§  Codifica 450 testi...
ğŸ’¾ Cache salvata (12.3 MB)
```

---

### **3ï¸âƒ£ Crea Chunk con Llama (OPZIONALE - Automatizzazione)**
```powershell
# Esempio: crea chunk per Day 50-55
python scripts\3_create_chunks_with_llama.py --range 50 55

# Oppure singolo giorno
python scripts\3_create_chunks_with_llama.py --days 100

# Test con pochi chunk
python scripts\3_create_chunks_with_llama.py --days 50 --max-chunks 3
```
**Cosa fa:**
- Legge trascrizioni originali da `Fonti/.../Originali/Pyramid.mathias/Day_X_Transcript.txt`
- Usa Llama per generare automaticamente:
  - Metadata (titoli, concetti, keywords)
  - Domande e risposte spirituali
  - Quote iconiche, formulas
- Salva chunk JSON in `Fonti/.../Processati/Pyramid Course/chunks/dayXX/`

**Quando eseguire:**
- âœ… Quando vuoi processare nuove trascrizioni automaticamente
- âœ… Alternativa alla creazione manuale con Copilot
- â­ï¸ Non necessario se hai giÃ  chunk manuali

**Note:**
- Usa automaticamente ultimo modello fine-tunato (se disponibile)
- Altrimenti usa Llama base pre-addestrato

**Output atteso:**
```
ğŸ¦™ Inizializzazione Chunk Creator con Llama...
âœ… Modello FINE-TUNATO caricato
   Checkpoint: ai_system/checkpoints/llama_rag_20251030/best_model/
ğŸ“„ Processamento: Day 50
   ğŸ“¦ Sezioni create: 5
   ğŸ¤– Generazione chunk con Llama...
âœ… Day 50 completato: 5 chunk creati
```

---

## ğŸ“ TRAINING E MIGLIORAMENTO MODELLO

### **4ï¸âƒ£ Crea Dataset Training (Ogni settimana/mese)**
```powershell
python scripts\4_create_training_dataset.py
```
**Cosa fa:**
- Carica conversazioni utenti da `ai_system/training_data/conversations/`
- Carica chunk RAG da `Fonti/.../chunks/`
- Crea campioni sintetici se poche conversazioni (<50)
- Split 80/10/10 (train/val/test)
- Salva in `ai_system/src/training/training_dataset/`

**Quando eseguire:**
- âœ… Dopo aver raccolto 20+ conversazioni utenti
- âœ… Ogni settimana per aggiornare dataset
- âœ… Prima di ogni fine-tuning (script 5)

**Output atteso:**
```
ğŸ“š Caricamento conversazioni...
âœ… Conversazioni caricate: 45
ğŸ“– Caricamento chunk RAG...
âœ… Chunk caricati: 450
ğŸ“Š DATASET CREATO:
   â€¢ Train: 480 samples
   â€¢ Val: 60 samples
   â€¢ Test: 60 samples
ğŸ’¾ Salvato in: ai_system/src/training/training_dataset/
```

---

### **5ï¸âƒ£ Fine-Tuning Llama (Training)**
```powershell
# Training completo (3 epoch)
python scripts\5_train_llama_rag.py --config llama-qlora --epochs 3

# Update veloce (2 epoch)
python scripts\5_train_llama_rag.py --config llama-qlora --epochs 2

# Training con piÃ¹ VRAM
python scripts\5_train_llama_rag.py --config llama-2-7b --epochs 3
```
**Cosa fa:**
- Carica Llama base (o ultimo checkpoint)
- Fine-tuning LoRA/QLoRA su dataset training
- Salva checkpoint in `ai_system/checkpoints/llama_rag_YYYYMMDD/`
- Early stopping se loss non migliora

**Quando eseguire:**
- âœ… Dopo aver creato/aggiornato dataset (script 4)
- âœ… Prima volta: 3 epoch (training completo)
- âœ… Aggiornamenti: 2 epoch (fine-tuning incrementale)

**Requisiti:**
- GPU con 6GB+ VRAM (config `llama-qlora`)
- GPU con 16GB+ VRAM (config `llama-2-7b`)
- Tempo: 1-3 ore

**Output atteso:**
```
ğŸ¦™ Caricamento modello Llama...
âœ… Modello caricato: Llama-2-7b-chat-hf
ğŸ“Š Dataset caricato: 480 train, 60 val
ğŸ“ Inizio training (3 epoch)...

Epoch 1/3:
  Train Loss: 1.234
  Val Loss: 1.156

Epoch 2/3:
  Train Loss: 0.987
  Val Loss: 0.945

Epoch 3/3:
  Train Loss: 0.876
  Val Loss: 0.912

âœ… Training completato!
ğŸ’¾ Best model salvato: ai_system/checkpoints/llama_rag_20251030/best_model/
```

---

## ğŸ¤– USO CHATBOT

### **6ï¸âƒ£ Chatbot con Llama**
```powershell
python scripts\6_chatbot.py
```
**Cosa fa:**
- Carica embeddings RAG (`2_generate_embeddings.py`)
- Carica Llama:
  - âœ… Ultimo checkpoint fine-tunato (se disponibile)
  - âœ… Modello base altrimenti
- Conversazione interattiva
- Salva conversazioni in `ai_system/training_data/conversations/`

**Auto-detection modello:**
- Script cerca automaticamente in `ai_system/checkpoints/llama_rag_*/`
- Usa checkpoint piÃ¹ recente
- Messaggio indica quale modello Ã¨ in uso

---

## ğŸ“Š WORKFLOW COMPLETO

### **Setup Iniziale (Una volta):**
```powershell
# 1. Download Llama (obbligatorio)
python scripts\1_download_llama.py --verify

# 2. Genera embeddings (se hai chunk pronti)
python scripts\2_generate_embeddings.py
```

### **Primo Fine-Tuning:**
```powershell
# 3. (Opzionale) Crea chunk automatici
python scripts\3_create_chunks_with_llama.py --range 1 10

# 4. Rigenera embeddings se hai creato nuovi chunk
python scripts\2_generate_embeddings.py

# 5. Usa chatbot per 20+ conversazioni
python scripts\6_chatbot.py

# 6. Crea dataset da conversazioni
python scripts\4_create_training_dataset.py

# 7. Fine-tuning (3 epoch)
python scripts\5_train_llama_rag.py --config llama-qlora --epochs 3
```

### **Ciclo di Miglioramento Continuo (Settimanale/Mensile):**
```powershell
# 1. Usa chatbot normalmente (salva conversazioni automaticamente)
python scripts\6_chatbot.py

# 2. Ogni 20-30 nuove conversazioni, rigenera dataset
python scripts\4_create_training_dataset.py

# 3. Fine-tuning incrementale (2 epoch)
python scripts\5_train_llama_rag.py --config llama-qlora --epochs 2

# Il chatbot userÃ  automaticamente il nuovo checkpoint
```

---

## ğŸ—‚ï¸ STRUTTURA FILE DOPO SETUP

```
spirituality.ai/
â”œâ”€â”€ scripts/                              # â† TUTTI GLI SCRIPT QUI
â”‚   â”œâ”€â”€ 1_download_llama.py              # â† Setup iniziale
â”‚   â”œâ”€â”€ 2_generate_embeddings.py         # â† Genera embeddings RAG
â”‚   â”œâ”€â”€ 3_create_chunks_with_llama.py    # â† Automatizzazione chunk
â”‚   â”œâ”€â”€ 4_create_training_dataset.py     # â† Prepara dati training
â”‚   â”œâ”€â”€ 5_train_llama_rag.py             # â† Fine-tuning
â”‚   â””â”€â”€ 6_chatbot.py                     # â† Chatbot principale
â”‚
â”œâ”€â”€ ai_system/
â”‚   â”œâ”€â”€ Embedding/
â”‚   â”‚   â””â”€â”€ embeddings_cache.pkl         # â† Cache vettori
â”‚   â”‚
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ training/
â”‚   â”‚       â””â”€â”€ training_dataset/        # â† Dataset generato
â”‚   â”‚           â”œâ”€â”€ train_data.json
â”‚   â”‚           â”œâ”€â”€ val_data.json
â”‚   â”‚           â””â”€â”€ test_data.json
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ Llama-2-7b-chat-hf/          # â† Modello base (da script 1)
â”‚   â”‚
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”œâ”€â”€ llama_rag_20251030/          # â† Primo fine-tuning
â”‚   â”‚   â”‚   â””â”€â”€ best_model/
â”‚   â”‚   â””â”€â”€ llama_rag_20251107/          # â† Secondo fine-tuning
â”‚   â”‚       â””â”€â”€ best_model/
â”‚   â”‚
â”‚   â””â”€â”€ training_data/
â”‚       â””â”€â”€ conversations/                # â† Conversazioni salvate
â”‚           â””â”€â”€ 2025-10-30/
â”‚
â”œâ”€â”€ BOT/
â”‚   â””â”€â”€ chatbot.py                       # â† Core chatbot (usato da script 6)
â”‚
â””â”€â”€ Fonti/
    â””â”€â”€ Autori/
        â””â”€â”€ Mathias de Stefano/
            â”œâ”€â”€ Originali/
            â”‚   â””â”€â”€ Pyramid.mathias/      # â† Trascrizioni grezze
            â”‚       â”œâ”€â”€ Day_1_Transcript.txt
            â”‚       â””â”€â”€ ...
            â”‚
            â””â”€â”€ Processati/
                â””â”€â”€ Pyramid Course/       # â† Chunk processati
                    â”œâ”€â”€ chunks/
                    â”‚   â”œâ”€â”€ day01/
                    â”‚   â”‚   â”œâ”€â”€ day01_chunk_001_tema.json
                    â”‚   â”‚   â””â”€â”€ ...
                    â”‚   â””â”€â”€ day02/
                    â””â”€â”€ metadata/
```

---

## âš™ï¸ CONFIGURAZIONI MODELLO

```powershell
# QLoRA (6GB VRAM) - Consigliato
--config llama-qlora

# Llama 2 (16GB VRAM) - PiÃ¹ veloce ma piÃ¹ VRAM
--config llama-2-7b

# Llama 3 (16GB VRAM) - Modello piÃ¹ recente
--config llama-3-8b
```

---

## ğŸ†˜ TROUBLESHOOTING

### **Errore: CUDA out of memory**
```powershell
# Usa QLoRA invece di full precision
--config llama-qlora

# Riduci batch size (modifica model_config.py)
batch_size = 1
gradient_accumulation_steps = 16
```

### **Errore: Model not found**
```powershell
# Assicurati di aver eseguito script 1
python scripts\1_download_llama.py --verify
```

### **Chatbot usa modello base invece di fine-tunato**
```powershell
# Verifica esistenza checkpoint
dir ai_system\checkpoints\llama_rag_*\best_model

# Se non esiste, esegui training
python scripts\5_train_llama_rag.py --config llama-qlora --epochs 3
```

---

## ğŸ“ˆ METRICHE DI SUCCESSO

**Primo Fine-Tuning:**
- Loss finale < 1.0
- Val Loss stabile (non aumenta)
- Chatbot risponde in modo coerente

**Miglioramento Continuo:**
- Loss diminuisce ad ogni training
- Risposte piÃ¹ pertinenti e contestuali
- Meno allucinazioni/errori

---

## ğŸ’¡ BEST PRACTICES

1. **Prima volta:** Usa 3 epoch per training completo
2. **Aggiornamenti:** Usa 2 epoch per fine-tuning incrementale
3. **Raccogli 20-30 conversazioni** prima di ogni training update
4. **Rigenera embeddings** ogni volta che crei nuovi chunk
5. **Backup checkpoint** importanti (copia cartella `checkpoints/`)
6. **Monitora loss:** se aumenta, riduci learning rate

---

## ğŸ¯ QUICK START

**Setup completo in 3 comandi:**
```powershell
# 1. Download Llama
python scripts\1_download_llama.py --verify

# 2. Genera embeddings
python scripts\2_generate_embeddings.py

# 3. Avvia chatbot
python scripts\6_chatbot.py
```

**Dopo 20+ conversazioni, migliora il modello:**
```powershell
# 4. Crea dataset
python scripts\4_create_training_dataset.py

# 5. Fine-tuning
python scripts\5_train_llama_rag.py --config llama-qlora --epochs 3
```

---

âœ… **Sistema pronto!** Ora hai un workflow chiaro e numerato per ogni operazione.
