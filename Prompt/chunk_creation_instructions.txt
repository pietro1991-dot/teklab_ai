================================================================================
üì¶ INSTRUCTIONS FOR COPILOT - CREATING RAG CHUNKS IN COMPLETE FORMAT
================================================================================

OBJECTIVE:
Create chunks in conversation format (messages: system/user/assistant) with 
extended metadata for training Spirituality AI RAG chatbot.

IMPORTANT:
- Each chunk is a COMPLETE conversation ready for training
- Each chunk is SELF-CONTAINED: messages + ALL metadata embedded in 1 JSON file
- LANGUAGE: Write EVERYTHING in ENGLISH (user content, assistant response, metadata)
- NO author citations in the response (use knowledge as if it were yours)
- IDENTICAL system prompt in all chunks (copied from Prompt/prompts_config.py)
- Extended metadata for robustness and training quality
- Separate files (metadata/keywords/quotes) AGGREGATE info from chunks, DON'T duplicate
- COMPLETE SESSION: When you receive files in chat, create EVERYTHING (chunks + aggregated files) without interruptions

================================================================================
üìÅ FOLDER STRUCTURE - CRITICAL RULES
================================================================================

‚ö†Ô∏è PYRAMID COURSE SPECIFIC STRUCTURE:

ROOT PATH: 
Fonti/Autori/Mathias de Stefano/Processati/Pyramid Course/

CORRECT STRUCTURE:
```
Pyramid Course/
‚îÇ
‚îú‚îÄ‚îÄ chunks/                                    ‚Üê Root for all chunks
‚îÇ   ‚îú‚îÄ‚îÄ day01/                                ‚Üê Separate folder per day
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ day01_chunk_001_tema.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ day01_chunk_002_tema.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ day01_chunk_003_tema.json
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ day02/                                ‚Üê NEW folder for day 2
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ day02_chunk_001_tema.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ day02_chunk_002_tema.json
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ day03/                                ‚Üê NEW folder for day 3
‚îÇ       ‚îî‚îÄ‚îÄ day03_chunk_001_tema.json
‚îÇ
‚îú‚îÄ‚îÄ metadata/                                  ‚Üê SIBLING folder to chunks/ (NOT inside!)
‚îÇ   ‚îú‚îÄ‚îÄ day01_metadata.json
‚îÇ   ‚îú‚îÄ‚îÄ day02_metadata.json
‚îÇ   ‚îî‚îÄ‚îÄ day03_metadata.json
‚îÇ
‚îú‚îÄ‚îÄ keywords/                                  ‚Üê SIBLING folder to chunks/ (NOT inside!)
‚îÇ   ‚îú‚îÄ‚îÄ day01_keywords.json
‚îÇ   ‚îî‚îÄ‚îÄ day02_keywords.json
‚îÇ
‚îú‚îÄ‚îÄ quotes/                                    ‚Üê SIBLING folder to chunks/ (NOT inside!)
‚îÇ   ‚îú‚îÄ‚îÄ day01_quotes.json
‚îÇ   ‚îî‚îÄ‚îÄ day02_quotes.json
‚îÇ
‚îî‚îÄ‚îÄ qa_pairs/                                  ‚Üê SIBLING folder to chunks/ (NOT inside!)
    ‚îú‚îÄ‚îÄ day01_qa.json
    ‚îî‚îÄ‚îÄ day02_qa.json
```

üö® CRITICAL PATH RULES:

1. ‚úÖ Each day gets OWN folder: chunks/dayXX/
   - Day 2 chunks go in: chunks/day02/ NOT chunks/day01/ ‚ùå
   
2. ‚úÖ Aggregated folders are SIBLINGS to chunks/, NOT subfolders
   - Correct: metadata/day03_metadata.json ‚úÖ
   - Wrong: chunks/day03/metadata/day03_metadata.json ‚ùå
   
3. ‚úÖ Aggregated files are FLAT (no day subfolders)
   - Correct: keywords/day03_keywords.json ‚úÖ
   - Wrong: keywords/day03/day03_keywords.json ‚ùå

================================================================================
üìÅ FILE STRUCTURE AND ORGANIZATION
================================================================================

üéØ SELF-CONTAINED CHUNKS (PRIMARY - ALWAYS CREATE):

File name: dayXX_chunk_NNN_descriptive_title.json
           or fileXX_chunk_NNN_descriptive_title.json

Location examples:
- Pyramid Course: chunks/day03/day03_chunk_001_tema.json
- Other works: chunks/file09/file09_chunk_004_ankles_feet_destiny.json

Each chunk contains ALREADY inside:
‚úÖ messages (system/user/assistant conversation)
‚úÖ complete metadata (base + extended)
‚úÖ keywords_primary/synonyms/relations
‚úÖ iconic_quotes
‚úÖ key_formulas
‚úÖ negative_examples
‚úÖ follow_up_questions
‚úÖ chain_of_thought
‚úÖ prerequisites, natural_followup
‚úÖ difficulty_level, tone, sentiment, question_type, user_intent
‚úÖ importance, relevance

üìã AGGREGATED FILES (SECONDARY - CREATE AFTER CHUNKS):

These files DON'T duplicate chunk data, but AGGREGATE and ENRICH:

1. metadata/dayXX_metadata.json (or fileXX_metadata.json)
   ‚Üí OVERVIEW of day/file: practices, affirmations, themes, sacred geometry
   ‚Üí Info that crosses all chunks of the file

2. keywords/fileXX_keywords.json
   ‚Üí ALL keywords from all file chunks aggregated
   ‚Üí Organized by theme for efficient retrieval

3. quotes/fileXX_quotes.json
   ‚Üí ALL quotes from all file chunks aggregated
   ‚Üí Organized by theme with context

4. qa_pairs/fileXX_qa.json (IMPORTANT!)
   ‚Üí ADDITIONAL Q&A that are NOT in the chunks
   ‚Üí Enrich training dataset with extra questions

================================================================================
üéØ COMPLETE JSON FORMAT
================================================================================

{
  "id": "file09_chunk_004_ankles_feet_destiny",
  
  "messages": [
    {
      "role": "system",
      "content": "[COPY ENTIRE SYSTEM PROMPT FROM Prompt/prompts_config.py - DON'T MODIFY]"
    },
    {
      "role": "user",
      "content": "Informative context (DON'T cite authors in response):\n\n[CHUNK] - [Section Title]\nConcepts: [list of key concepts]\nüìå Quote: \"[iconic quote if present]\"\n\nComplete text: [Original chunk text reworked for clarity]\n\n---\n\nQuestion: [Natural question a user would ask about this theme]\n\nRespond as an expert spiritual guide:\n- Wise and illuminating\n- Explain spiritual principles accessibly\n- Give concrete practices with specific exercises/meditations\n- NO author citations (use info as if it were yours)\n- Focus on TRANSFORMING the person's consciousness"
    },
    {
      "role": "assistant",
      "content": "[ARTICULATED RESPONSE]\n\n[1. DIRECT ANSWER (1-2 sentences answering immediately)]\n\n[2. SPIRITUAL PRINCIPLE (clear and deep explanation)]\n\n[3. CONCRETE PRACTICES]\n\n1. [PRACTICE 1] (duration)\n   ‚Ä¢ Step 1\n   ‚Ä¢ Step 2\n   ‚Ä¢ Step 3\n\n2. [PRACTICE 2]\n   ‚Ä¢ Step 1\n   ‚Ä¢ Step 2\n\n3. [PRACTICE 3]\n   ‚Ä¢ ...\n\n[4. KEY UNDERSTANDING / BENEFITS]\n\n[5. SIGNS / INDICATORS]\n\n[6. REMEMBER (final empowering message)]"
    }
  ],
  
  "metadata": {
    "chunk_id": "file09_chunk_004_ankles_feet_destiny",
    "file_number": 9,                    // or "chapter_number": 1
    "file_title": "Ankles - Mind Week",  // or "chapter_title": "..."
    "chunk_number": 4,
    "chunk_title": "Ankles and Feet: The Destiny We Choose",
    "author": "Mathias de Stefano",     // Author name
    "work": "Pyramid Course - 42 Days Initiation",
    
    "key_concepts": [
      "Concept 1 clearly formulated",
      "Concept 2 with specific detail",
      "Concept 3 practical action",
      "Concept 4 deep understanding",
      "Concept 5 expected result"
      // 5-10 concepts
    ],
    
    "keywords_primary": [
      "primary keyword 1",
      "primary keyword 2",
      "primary keyword 3"
      // 5-8 keywords
    ],
    
    "keywords_synonyms": {
      "term1": ["synonym1", "synonym2", "synonym3"],
      "term2": ["variant1", "variant2"],
      "term3": ["alternative1", "alternative2"]
      // For each primary keyword, list 3-5 synonyms/variants
    },
    
    "keywords_relations": {
      "keyword1": ["relation1", "relation2", "relation3"],
      "keyword2": ["connection1", "connection2"]
      // Semantic connections between concepts
    },
    
    "iconic_quotes": [
      "Memorable quote 1 from original text",
      "Key quote 2 that synthesizes principle",
      "Impactful phrase 3 that inspires"
      // 2-4 quotes
    ],
    
    "key_formulas": [
      "Formula 1 = Concept A > Concept B",
      "Formula 2 = Input √ó Action ‚Üí Output",
      "Principle 3: Condition ‚Üí Result"
      // 3-5 synthetic formulas/principles
    ],
    
    "negative_examples": {
      "question": "How can I [chunk theme]?",
      "answers_to_avoid": [
        "‚ùå Wrong answer 1 (why it's wrong)",
        "‚ùå Wrong answer 2 (why it's wrong)",
        "‚ùå Wrong answer 3 (why it's wrong)"
      ],
      "correct_answer": "Summary of correct answer with key elements"
    },
    
    "follow_up_questions": [
      "Natural follow-up question 1?",
      "Deepening question 2?",
      "Common doubt 3?",
      "Practical application 4?",
      "Specific case 5?"
      // 5-7 questions user might ask after
    ],
    
    "chain_of_thought": {
      "question": "Why [key principle of chunk]?",
      "reasoning": [
        "Step 1: Initial premise ‚Üí logical consequence",
        "Step 2: From previous consequence ‚Üí new deduction",
        "Step 3: Connection with practical experience",
        "Step 4: Integration with other principles",
        "Conclusion: Final synthesis answering the question"
      ]
    },
    
    "prerequisites": [
      "file08_chunk_003_preparatory_theme",
      "chap01_base_concept"
      // Chunks/chapters better to read before (if applicable)
    ],
    
    "natural_followup": [
      "file10_chunk_001_next_theme",
      "chap03_deepening"
      // Related chunks/chapters to explore after
    ],
    
    "difficulty_level": "beginner",  // or "intermediate", "advanced"
    "tone": ["illuminating", "practical", "compassionate"],
    "sentiment": "empowering",  // or "liberating", "grounding", "challenging"
    
    "question_type": "practical-philosophical",  // or "theoretical", "emotional", "meditative"
    "user_intent": [
      "concept understanding",
      "daily practices",
      "personal transformation"
      // What user really seeks
    ],
    
    "importance": 0.92,  // 0-1 (how central is this chunk)
    "relevance": 10,     // 1-10 (how useful for average user)
    "language": "en"     // üåç MULTILINGUAL: "en", "it", "es" - language of the chunk content
  }
}

üåç IMPORTANT - LANGUAGE FIELD:
================================================================================
ALWAYS include "language" field in metadata:

‚Ä¢ "en" = English content
‚Ä¢ "it" = Italian content  
‚Ä¢ "es" = Spanish content

EXAMPLES:

‚úÖ ENGLISH CHUNK:
"metadata": {
  "chunk_id": "day01_chunk_001_crown_chakra",
  "language": "en",
  ...
}

‚úÖ ITALIAN CHUNK:
"metadata": {
  "chunk_id": "giorno01_chunk_001_chakra_corona",
  "language": "it",
  ...
}

‚úÖ SPANISH CHUNK:
"metadata": {
  "chunk_id": "dia01_chunk_001_chakra_corona",
  "language": "es",
  ...
}

‚ö†Ô∏è MANTRAS AND SACRED SOUNDS:
Keep mantras/sounds in ORIGINAL form regardless of chunk language:
‚Ä¢ "I CAN" (not "IO POSSO" or "YO PUEDO")
‚Ä¢ "MA" vibration (not "MA" in other languages)
‚Ä¢ "OM" / "AUM" (universal Sanskrit)
‚Ä¢ Bija mantras (LAM, VAM, RAM, YAM, HAM, OM)

The system will automatically translate responses to user's query language while 
preserving mantras in their original sacred form.

================================================================================

================================================================================
üìù CONTENT WRITING GUIDELINES
================================================================================

SYSTEM PROMPT:
‚Ä¢ Copy ENTIRE system prompt from Prompt/prompts_config.py
‚Ä¢ DON'T modify anything
‚Ä¢ Includes few-shot examples to teach response format

USER CONTENT:
‚Ä¢ Structure: Context + Concepts + Quote + Question
‚Ä¢ Context must be CLEAR and SELF-CONTAINED
‚Ä¢ Key concepts listed to guide response
‚Ä¢ Question formulated as a real user would ask it
‚Ä¢ üåç WRITE IN ENGLISH (all user content in English)

ASSISTANT CONTENT (the response):
‚Ä¢ Max 200-300 words (can reach 400 if complex guided practice)
‚Ä¢ üåç WRITE IN ENGLISH (entire response in English)
‚Ä¢ Structure ALWAYS:
  1. Direct answer (1-2 sentences)
  2. Spiritual principle explained
  3. Concrete STEP-BY-STEP practices
  4. Benefits/Key understanding
  5. Final empowering message
‚Ä¢ NO author citations (e.g.: "According to X...", "In the book Y...")
‚Ä¢ YES universal expressions (e.g.: "Spiritual traditions teach...")
‚Ä¢ Speak in FIRST PERSON as guide: "I invite you to...", "It's essential..."
‚Ä¢ Always PRACTICAL + DEEP (not just theory, not just practice)

GENERAL TONE:
‚úÖ Wise but accessible
‚úÖ Compassionate and non-judgmental
‚úÖ Inspiring and empowering
‚úÖ Direct and clear (no beating around the bush)
‚úÖ Focus on real TRANSFORMATION

‚ùå NOT academic or detached
‚ùå NOT vague or generic
‚ùå NOT judgmental or prescriptive
‚ùå NOT author citations in response body

================================================================================
üîß METADATA - HOW TO FILL THEM
================================================================================

KEY_CONCEPTS:
‚Ä¢ Formulate as COMPLETE SENTENCES not single words
‚Ä¢ üåç IN ENGLISH
‚Ä¢ GOOD example: "Feet contain information about direction and chosen destiny"
‚Ä¢ BAD example: "feet, destiny, direction"
‚Ä¢ 5-10 concepts capturing chunk essence

KEYWORDS_PRIMARY:
‚Ä¢ Terms/phrases a user would use to search for this content
‚Ä¢ üåç IN ENGLISH
‚Ä¢ 2-4 words per keyword
‚Ä¢ 5-8 keywords total
‚Ä¢ Example: "ankles destiny portal", "core earth meditation"

KEYWORDS_SYNONYMS:
‚Ä¢ For EACH primary keyword, list 3-5 variants/synonyms
‚Ä¢ üåç IN ENGLISH
‚Ä¢ Include: direct synonyms, related terms, different ways of saying
‚Ä¢ Example: "destiny": ["direction", "purpose", "path", "life journey"]

KEYWORDS_RELATIONS:
‚Ä¢ Semantic connections between concepts
‚Ä¢ What naturally connects to what
‚Ä¢ Example: "meditation": ["breath", "silence", "observation"]

ICONIC_QUOTES:
‚Ä¢ MEMORABLE phrases from original text
‚Ä¢ That synthesize a key principle
‚Ä¢ That inspire and stay in mind
‚Ä¢ 2-4 quotes (no more)

KEY_FORMULAS:
‚Ä¢ Principles synthesized in formula/equation format
‚Ä¢ Example: "Destiny = Intention √ó Present Action"
‚Ä¢ Example: "Presence in steps > Speed of arrival"
‚Ä¢ 3-5 formulas

NEGATIVE_EXAMPLES:
‚Ä¢ What NOT to say / common wrong approaches
‚Ä¢ Serves to TEACH the model what to avoid
‚Ä¢ 3-4 examples of wrong answers + explanation why
‚Ä¢ Always include the CORRECT answer

FOLLOW_UP_QUESTIONS:
‚Ä¢ Questions user would naturally ask after
‚Ä¢ Common doubts
‚Ä¢ Clarification requests
‚Ä¢ Practical deepenings
‚Ä¢ 5-7 questions

CHAIN_OF_THOUGHT:
‚Ä¢ Only for COMPLEX concepts requiring reasoning
‚Ä¢ Shows the logical PATH step-by-step
‚Ä¢ Teaches the model how to ARGUE
‚Ä¢ 4-6 reasoning steps

PREREQUISITES / NATURAL_FOLLOWUP:
‚Ä¢ Connections with other chunks of course/book
‚Ä¢ Prerequisites: what's better to know before
‚Ä¢ Followup: what to explore after to continue
‚Ä¢ Use chunk_id of other chunks

DIFFICULTY_LEVEL:
‚Ä¢ beginner: base concepts, accessible to all
‚Ä¢ intermediate: requires understanding base principles
‚Ä¢ advanced: deep concepts, intense practices

TONE:
‚Ä¢ List 2-4 adjectives describing the tone
‚Ä¢ Example: ["illuminating", "practical", "compassionate"]
‚Ä¢ Other: "transformative", "grounding", "empowering", "ritual"

QUESTION_TYPE:
‚Ä¢ What type of query is it
‚Ä¢ practical: "how do I..."
‚Ä¢ philosophical: "why/what does it mean..."
‚Ä¢ emotional: "how to manage feelings..."
‚Ä¢ meditative: "guided practice..."

USER_INTENT:
‚Ä¢ What user REALLY seeks behind the question
‚Ä¢ Example: "understanding destiny", "daily practices", "overcoming block"

IMPORTANCE / RELEVANCE:
‚Ä¢ importance (0-1): how central in corpus (0.9+ = fundamental)
‚Ä¢ relevance (1-10): how useful for average user (10 = everyone must know)

================================================================================
‚úÖ CHECKLIST BEFORE SAVING
================================================================================

CONTENT:
[ ] System prompt copied complete from prompts_config.py
[ ] User content with context + concepts + quote + question
[ ] Assistant content 200-300 words, 5-part structure
[ ] NO author citations in response
[ ] Concrete step-by-step practices present
[ ] Wise, compassionate, practical tone

BASE METADATA:
[ ] Unique and descriptive chunk_id
[ ] Correct file/chapter_number
[ ] Author and work filled
[ ] 5-10 key_concepts (complete sentences)
[ ] 5-8 keywords_primary
[ ] 2-4 iconic_quotes
[ ] 3-5 key_formulas
[ ] Importance and relevance assigned

EXTENDED METADATA:
[ ] keywords_synonyms for each primary keyword (3-5 synonyms)
[ ] keywords_relations between concepts
[ ] negative_examples with 3-4 wrong answers + correct
[ ] follow_up_questions (5-7 natural questions)
[ ] chain_of_thought if complex concept
[ ] prerequisites and natural_followup if applicable
[ ] difficulty_level, tone, sentiment, question_type
[ ] user_intent what user seeks

VALID JSON:
[ ] Correct JSON syntax (commas, brackets, quotes)
[ ] No trailing comma in last element of array/object
[ ] Multiline strings with \n escaped
[ ] Tested with online JSON validator if uncertain

================================================================================
üöÄ CHUNK CREATION WORKFLOW
================================================================================

‚ö° IMPORTANT: COMPLETE EVERYTHING IN ONE SESSION!

When you receive shared files in chat (transcript/original text from a file):
‚Üí You must create EVERYTHING in the same session without interruptions:
  ‚Ä¢ PHASE 1: All chunks of the file (4-7 chunks)
  ‚Ä¢ PHASE 2: All aggregated files (metadata, keywords, quotes, qa_pairs)

DON'T stop after 1-2 chunks asking for confirmation!
Proceed until total completion of the file.

---

PHASE 1: CREATING SELF-CONTAINED CHUNKS (PRIORITY)

1. READ transcript/original text of file/chapter
2. IDENTIFY 4-7 main themes
3. For EACH theme:
   a. Create 1 SELF-CONTAINED chunk with complete structure
   b. Write system/user/assistant conversation IN ENGLISH
   c. Fill ALL base + extended metadata INSIDE the chunk
   d. Verify valid JSON
   e. SAVE in: Fonti/Autori/[Author]/Processati/[Work]/chunks/fileXX/

‚úÖ At this point you have COMPLETE chunks ready for training!

PHASE 2: CREATING AGGREGATED FILES (AFTER all file chunks ready)

4. Create metadata/fileXX_metadata.json
   ‚Üí File overview with practices, affirmations, cross-cutting themes
   ‚Üí DON'T duplicate chunk metadata, AGGREGATE higher-level info

5. Create keywords/fileXX_keywords.json
   ‚Üí COLLECT all keywords_primary from all file chunks
   ‚Üí Organize by theme for efficient retrieval

6. Create quotes/fileXX_quotes.json
   ‚Üí COLLECT all iconic_quotes from all file chunks
   ‚Üí Organize by theme with application context

7. Create qa_pairs/fileXX_qa.json (IMPORTANT!)
   ‚Üí ADDITIONAL Q&A that are NOT covered by chunks
   ‚Üí Alternative questions, edge cases, deepenings
   ‚Üí These enrich training dataset

‚úÖ ONLY AFTER completing PHASE 2 the file is ready!

================================================================================
üí° FINAL TIPS
================================================================================

‚Ä¢ Fast system: Copy existing chunk template (e.g.: file09_chunk_004) and modify
‚Ä¢ SELF-CONTAINED chunk: must work standalone without external files
‚Ä¢ CLEAR user content: complete context without dependencies
‚Ä¢ PRACTICAL assistant: always give concrete steps not just theory
‚Ä¢ Rich metadata INSIDE chunk: more embedded info = better training
‚Ä¢ Valid JSON: use online validator if uncertain
‚Ä¢ Final test: ask copilot "explain this chunk" to verify clarity
‚Ä¢ üåç EVERYTHING IN ENGLISH: user content, assistant response, metadata
‚Ä¢ ‚ö° COMPLETE SESSION: When you receive files in chat, complete EVERYTHING before stopping

REMEMBER:
‚úÖ Messages format (system/user/assistant) NOT old question/answer format
‚úÖ IDENTICAL system prompt in all chunks
‚úÖ NO author citations in assistant response
‚úÖ YES concrete step-by-step practices
‚úÖ Extended metadata not optional - essential for training
‚úÖ Each chunk is SELF-CONTAINED - all metadata embedded inside
‚úÖ Separate files (metadata/keywords/quotes/qa) AGGREGATE, DON'T duplicate
‚úÖ Training reads 1 file per chunk ‚Üí maximum efficiency
‚úÖ üåç ENGLISH LANGUAGE for all content (user/assistant/metadata)
‚úÖ ‚ö° COMPLETE PHASE 1 + PHASE 2 in one session when you receive files in chat

================================================================================
End of instructions. Use this as reference every time you create new chunks!
================================================================================
