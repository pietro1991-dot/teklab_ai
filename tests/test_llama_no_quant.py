#!/usr/bin/env python3
"""
Test Llama RAG senza quantizzazione (per GTX 1050 Ti)
"""
import sys
from pathlib import Path
import torch

# Setup paths
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR
sys.path.insert(0, str(PROJECT_ROOT / "ai_system" / "src"))

print("üîß Test caricamento Llama RAG Model (NO quantization)...")

try:
    # Test import
    print("üì¶ Importing modules...")
    from models.llama_rag_model import LlamaRAGModel, create_llama_rag_model
    print("‚úÖ Import successful!")
    
    # Test config
    print("‚öôÔ∏è  Loading config...")
    from config.model_config import get_config
    config = get_config('llama-2-7b')  # Config base senza quantizzazione
    print("‚úÖ Config loaded!")
    
    # Test model path
    model_path = PROJECT_ROOT / "ai_system" / "models" / "Llama-2-7b-chat-hf"
    print(f"üìÇ Model path: {model_path}")
    print(f"   Exists: {'‚úÖ' if model_path.exists() else '‚ùå'}")
    
    if model_path.exists():
        print("\nü¶ô Creating LlamaRAGModel (NO quantization)...")
        
        # Crea modello SENZA quantizzazione per evitare problemi bitsandbytes
        model = LlamaRAGModel(
            llama_model_name=str(model_path),
            use_quantization=False,  # DISABILITA quantizzazione
            use_lora=False,          # DISABILITA LoRA per ora
            torch_dtype=torch.float16,  # Usa float16 per risparmiare memoria
            device_map="cuda" if torch.cuda.is_available() else "cpu"
        )
        
        print("‚úÖ Model created successfully!")
        print(f"   Model name: {model.llama_model_name}")
        print(f"   Device: {model.llama.device}")
        
        # Test simple generation
        print("\nüß™ Testing generation...")
        test_response = model.generate(
            query="Ciao, come stai?",
            context_chunks=["Questo √® un test di generazione."],
            max_new_tokens=20  # Ridotto per test veloce
        )
        print(f"‚úÖ Generation test: {test_response}")
        
        print("\nüéâ Test completato con successo!")
        
    else:
        print(f"‚ùå Model directory not found: {model_path}")
        
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    print("üí° Make sure all dependencies are installed:")
    print("   pip install transformers accelerate sentence-transformers")
    
except Exception as e:
    print(f"‚ùå Error: {e}")
    import traceback
    traceback.print_exc()